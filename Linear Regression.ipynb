{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JKdfRsPZOx7-"
      },
      "source": [
        "all these functions here are only made using NumPy, without using any other libraries like pandas, scikit-learn, or scipy. I run a complete machine learning process from preprocessing to model performance testing by using the functions to develop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9BPzS0g9Ox7-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "svj3G7hj4ZxY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2HAUc00Wmu0E"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing = fetch_california_housing(as_frame=False)\n",
        "\n",
        "X = california_housing.data\n",
        "y = california_housing.target"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-txQY1eUoWeg"
      },
      "source": [
        "using both features and labels. To handle it correctly, it need to be familiar with its axis concept as it no longer has indices and columns that you can check by printing the variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u4KbMNxMm9Oi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "          37.88      , -122.23      ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "          37.86      , -122.22      ],\n",
              "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "          37.85      , -122.24      ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "          39.43      , -121.22      ],\n",
              "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "          39.43      , -121.32      ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "          39.37      , -121.24      ]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9rTO_NYMNHlg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbj_IpkHOx8A"
      },
      "source": [
        "### 1. Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EE0ALwTyOx8A"
      },
      "source": [
        "The first task is to open the dataset and preprocess it into the form that the model can understand. It involves imputation, train_test_split, standardization, and normalization. Some functions are already covered by the first lab."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t2uFZSUuoh9t"
      },
      "source": [
        "\n",
        "- Standardization: Make features have the same standard deviaton and mean.\n",
        "\n",
        "- Normalization: Make the range of value normalized into [0, 1]. This means that each column's minimum value should be zero and maximum value should be one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bQRVVievOx8A"
      },
      "outputs": [],
      "source": [
        "def standardize(data):\n",
        "  \"\"\"\n",
        "  Input: NumPy ndarray\n",
        "  Output: NumPy ndarray with column mean == 0 and std == 1\n",
        "  \"\"\"\n",
        "  data_standard = (data - data.mean(axis=0)) / data.std(axis=0)\n",
        "  return data_standard\n",
        "\n",
        "def normalize(data):\n",
        "  \"\"\"\"\n",
        "  Input: NumPy ndarray\n",
        "  Output: NumPy ndarray with column min == 0 and max == 1\n",
        "  \"\"\"\n",
        "  min_value = data.min(axis=0)\n",
        "  max_value = data.max(axis=0)\n",
        "  data_output = (data - min_value) / (max_value - min_value)\n",
        "  return data_output\n",
        "\n",
        "def standardize(data):\n",
        "  \"\"\"\n",
        "  Input: Pandas DataFrame\n",
        "  Output: Pandas DataFrame with mean == 0 and std == 1\n",
        "  \"\"\"\n",
        "  mean = np.mean(data, axis=0)\n",
        "  std = np.std(data, axis=0)\n",
        "  data_new = (data - mean) / std\n",
        "  return data_new\n",
        "\n",
        "def normalize(data):\n",
        "  \"\"\"\"\n",
        "  Input: Pandas DataFrame\n",
        "  Output: Pandas DataFrame with min == 0 and max == 1\n",
        "  \"\"\"\n",
        "\n",
        "  return (data - np.min(data, axis=0))/(np.max(data, axis=0) - np.min(data, axis=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4WgGQ0o_9G"
      },
      "source": [
        "Let's apply both functions separately and create X_standardized and X_normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2qf7fOZG54MA"
      },
      "outputs": [],
      "source": [
        "X_standardized = standardize(X)\n",
        "X_normalized = normalize(X)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "So46vKNl53KL"
      },
      "source": [
        "Creating a function to check the dataset's min, max, mean, std of each feature. You can re-use your lab function (**describe**) but this time you are not allowed to use Pandas DataFrame. There is no expected format for this function if you are successfully able to plot four statistics (min, max, mean, std). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l9BqVsG36Tsl"
      },
      "outputs": [],
      "source": [
        "def describe(data):\n",
        "  \"\"\"\n",
        "  Describe four statistics of the dataset.\n",
        "  \n",
        "  Input: NumPy ndarray\n",
        "  Output: vertical min, max, mean, standard deviation\n",
        "  \"\"\"\n",
        "  \n",
        "  print(\"Min: \", np.min(data, axis=0))\n",
        "  print(\"Max: \", np.max(data, axis=0))\n",
        "  print(\"Mean: \", np.mean(data, axis=0))\n",
        "  print(\"Std: \", np.std(data, axis=0))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FZEPPjpJ6W3B"
      },
      "source": [
        "Using this function, let's check if your **standardize** and **normalize** functions are correctly working. \n",
        "- ** output should be the same as the one below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NY6wtki6c84",
        "outputId": "945364b8-7158-4052-a701-a279cfef5ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [-1.77429947 -2.19618048 -1.8523186  -1.61076772 -1.25612255 -0.22899997\n",
            " -1.447568   -2.38599234]\n",
            "Max:  [  5.85828581   1.85618152  55.16323628  69.57171326  30.25033022\n",
            " 119.41910319   2.95806762   2.62528006]\n",
            "Mean:  [ 6.60969987e-17  5.50808322e-18  6.60969987e-17 -1.06030602e-16\n",
            " -1.10161664e-17  3.44255201e-18 -1.07958431e-15 -8.52651283e-15]\n",
            "Std:  [1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "describe(X_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7-p5vdl3H4F",
        "outputId": "b179dea5-39dd-4eab-8b1e-ade4f6160794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Max:  [1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Mean:  [0.23246376 0.54195071 0.03248795 0.02262871 0.03986874 0.00191395\n",
            " 0.32857188 0.47612505]\n",
            "Std:  [0.13101721 0.24676966 0.01753907 0.0140484  0.03173953 0.00835784\n",
            " 0.226982   0.19955012]\n"
          ]
        }
      ],
      "source": [
        "describe(X_normalized)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mj47zZ264Az0"
      },
      "source": [
        "dividing the dataset into two parts: {a training set, a test set} and only use the training set to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ORFET61FbZVy"
      },
      "outputs": [],
      "source": [
        "def train_test_split(X, y, test_ratio = 0.3):\n",
        "  # simulation\n",
        "  # cross-val\n",
        "  \n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: a set of features\n",
        "    - y: corresponding labels\n",
        "    - test_ratio: ratio of the test set\n",
        "    \n",
        "  Output:\n",
        "    - X_train: separated training instances\n",
        "    - X_test: separated test instances\n",
        "    - y_train: separated training labels\n",
        "    - y_test: separated test labels\n",
        "  \n",
        "  1. Randomly shuffle the indices of the data instances\n",
        "  2. Divide the indices into two parts with the ratio of [1-test ratio:test ratio]\n",
        "  3. Select training instances and labels with the first set of indices and test instances and labels with the second set of indices\n",
        "  4. Return the training set and the test set\n",
        "  \"\"\"\n",
        "  #np.random.seed(12345)\n",
        "  rng = np.random.permutation(len(X))\n",
        "  test_size = int(len(X)*(test_ratio))\n",
        "  train_ind = rng[test_size:]\n",
        "  test_ind = rng[:test_size]\n",
        "  return X[train_ind] , X[test_ind], y[train_ind], y[test_ind]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "twOo6_yniUGO"
      },
      "source": [
        "Spliting dataset into training and test sets with `test ratio = 0.3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f-iSb7IoijO1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d9PK6RGbkK7O"
      },
      "source": [
        "After applying train_test_split function, you can check the shape of each subset. The training set should have 14,448 rows while the test set might have 6,192 records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bk_pMMo-iquK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14448, 8), (6192, 8), (14448,), (6192,))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7T8JBhsTj00O"
      },
      "source": [
        " Creating two functions (**apply_standardization**, **apply_normalization**) that uses training set's statistics and apply standardization or normalization to both sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XLs3P181kYHA"
      },
      "outputs": [],
      "source": [
        "def apply_standardization(X_train, X_test):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_train: training instances\n",
        "    - X_test: test instances\n",
        "\n",
        "  Output:\n",
        "    - X_train_standardized\n",
        "    - X_test_standardized\n",
        "\n",
        "  Use training set's mean and standard deviation to standardize both training and test sets\n",
        "  \"\"\"\n",
        "  mean = np.mean(X_train, axis=0)\n",
        "  std = np.std(X_train, axis=0)\n",
        "  X_train_standardized = (X_train - mean) / std\n",
        "  X_test_standardized = (X_test - mean) / std\n",
        "  return X_train_standardized, X_test_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sOx7Kd221jRq"
      },
      "outputs": [],
      "source": [
        "def apply_normalization(X_train, X_test):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_train\n",
        "    - X_test\n",
        "\n",
        "  Output:\n",
        "    - X_train_standardized\n",
        "    - X_test_standardized\n",
        "  \"\"\"\n",
        "  max_value = np.max(X_train, axis=0)\n",
        "  min_value = np.min(X_train, axis=0)\n",
        "  X_train_standardized = (X_train - min_value) / (max_value - min_value)\n",
        "  X_test_standardized = (X_test - min_value) / (max_value - min_value)\n",
        "  return X_train_standardized, X_test_standardized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujWQ84ZFCa10"
      },
      "source": [
        "- Apply two functions (**apply_standardization**, **apply_normalization**) to created standardized and normalized datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Cw8tjyoCtnqI"
      },
      "outputs": [],
      "source": [
        "X_train_standardized, X_test_standardized = apply_standardization(X_train, X_test)\n",
        "X_train_normalized, X_test_normalized = apply_normalization(X_train, X_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "efxhH-DvCxBx"
      },
      "source": [
        "Checking the statistics using describe method. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ch5zQTDDDugQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [-1.77984117 -2.11947543 -1.75865295 -1.41639425 -1.21807626 -0.20527725\n",
            " -1.43606933 -2.39547596]\n",
            "Max:  [  5.88589575   1.85028562  52.37164895  64.61802314  29.37600436\n",
            " 106.24817184   2.97788143   2.52307343]\n",
            "Mean:  [-9.39866263e-15  1.71973915e-16 -7.06439241e-15 -1.49168331e-14\n",
            "  3.25159796e-17 -4.72230920e-16 -5.66941289e-14  1.80664822e-15]\n",
            "Std:  [1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "describe(X_train_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8qyxhAClDx7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [-1.77984117 -2.19887065 -1.74225417 -1.49805937 -1.21378885 -0.1737262\n",
            " -1.44076502 -2.33561532]\n",
            "Max:  [ 5.88589575  1.85028562 19.50893121 20.21319655 10.14183798 42.77983604\n",
            "  2.97788143  2.61286439]\n",
            "Mean:  [ 0.00721618 -0.01475838 -0.00023439 -0.00645906  0.00557054 -0.00510376\n",
            "  0.03692658 -0.03626547]\n",
            "Std:  [1.01438783 0.9972842  0.81925066 0.73644982 0.89984358 0.55256454\n",
            " 1.00933777 0.99758704]\n"
          ]
        }
      ],
      "source": [
        "describe(X_test_standardized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_tTsEozJ2_3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Max:  [1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Mean:  [0.23218135 0.53390504 0.03248925 0.02144933 0.03981412 0.00192833\n",
            " 0.32534784 0.48702895]\n",
            "Std:  [0.1304506  0.25190433 0.01847394 0.01514362 0.03268606 0.00939378\n",
            " 0.22655441 0.20331198]\n"
          ]
        }
      ],
      "source": [
        "describe(X_train_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bNplCpND3Byu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min:  [ 0.         -0.02        0.00030295 -0.00123671  0.00014014  0.00029638\n",
            " -0.00106383  0.01217039]\n",
            "Max:  [1.         1.         0.39289609 0.32755026 0.37131086 0.40379258\n",
            " 1.         1.01825558]\n",
            "Mean:  [0.23312271 0.53018734 0.03248492 0.02135152 0.03999619 0.00188039\n",
            " 0.33371371 0.47965575]\n",
            "Std:  [0.1323275  0.25122021 0.01513479 0.01115251 0.02941234 0.00519067\n",
            " 0.22866992 0.20282139]\n"
          ]
        }
      ],
      "source": [
        "describe(X_test_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgG7BAsDOx8B"
      },
      "source": [
        "### 2. Linear regression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aDLWBj56D6P6"
      },
      "source": [
        "Now it is ready to put the dataset to train a model. \n",
        "\n",
        "- Creating the **solver** function that creates a linear regression line and return the coefficents. \n",
        "-  **all available features** of the dataset are used.\n",
        "- adding one column representing a bias to your feature matrix.\n",
        "\n",
        "The normal equation can be represented as follows:\n",
        "\n",
        "$\\theta = (\\textbf{X}^T \\cdot \\textbf{X})^{-1} \\cdot \\textbf{X}^T \\cdot \\textbf{y}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6EkjV6APOx8C"
      },
      "outputs": [],
      "source": [
        "def solver(X, y):\n",
        "  \"\"\"\n",
        "  Get the weights and bias of linear regression classifier on the input dataset (X, y).\n",
        "\n",
        "  Input: \n",
        "   - X: a set of features\n",
        "   - y: labels\n",
        "  Output:\n",
        "   - theta: weights and bias of the linear regression\n",
        "  \"\"\"\n",
        "  bias = np.ones([X.shape[0],1])\n",
        "  data_X = np.concatenate([X,bias],axis=1)\n",
        "  normal_equation = np.linalg.inv(data_X.T @ data_X) @ data_X.T @ y\n",
        "  return normal_equation\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xWZhZW4rExeQ"
      },
      "source": [
        "\n",
        "- Runing the **solve** function on **X_train_standardized** and **y_train** and save the result to **theta**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_8ETLDgE_5p",
        "outputId": "390908bc-5d45-4e55-f9c3-5b043bc2f0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.82068913  0.12615715 -0.25578635  0.30210798 -0.00378871 -0.0448\n",
            " -0.90409719 -0.87281663  2.06391117]\n"
          ]
        }
      ],
      "source": [
        "theta = solver(X_train_standardized, y_train)\n",
        "print(theta)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dQDfYDDxF9o5"
      },
      "source": [
        "- Creating the **predict** function which put each instance into the regression equation to predict the value. **DO NOT USE ANY LOOP**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p-JxOI09ledN"
      },
      "outputs": [],
      "source": [
        "def predict(X, theta):\n",
        "  \"\"\"\n",
        "  Input: \n",
        "   - X: data instances to predict\n",
        "   - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "   - y_hat: predicted values (X @ weight) + bias\n",
        "  \"\"\"\n",
        "  # bias = np.ones([X.shape[0],1])\n",
        "  # data_X = np.concatenate([X,bias],axis=1)\n",
        "  # result = np.dot(data_X, theta)\n",
        "\n",
        "\n",
        "  weight = theta[:-1]\n",
        "  bias = theta[-1:]\n",
        "  y_hat = np.dot(X, weight) + bias\n",
        "\n",
        "  return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "psp-L1wGRslu"
      },
      "outputs": [],
      "source": [
        "#This predict function should be able to return the predicted value of the housing price. Then now you might want to return the mean squared error (and its variants) of the whole model. There can be many different metrics but here you will measure the rooted mean squared error (RMSE). RMSE can be calculated as follows: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljB3uUqjWPbw"
      },
      "source": [
        "$RMSE = \\sqrt{\\frac{1}{n}\\sum_{t=1}^{n}(\\hat{y}_t - y_t)^2} $.\n",
        "\n",
        "Note that $\\hat{y}$ is a predicted label and $y$ is a true label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTnVQGPWfBv"
      },
      "source": [
        "- Create a function **rooted_mean_squared_error** that calculates the RMSE value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "laAN9bTMOx8C"
      },
      "outputs": [],
      "source": [
        "def rooted_mean_squared_error(X, y, theta):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_test: data instances to test\n",
        "    - y_test: true class labels of the corresponding data instances (X_test)\n",
        "    - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "    - RMSE: the RMSE score\n",
        "\n",
        "  Use predict function to calculate our predicted values.\n",
        "  \"\"\"\n",
        "  y_hat = predict(X, theta)\n",
        "  RMSE = np.sqrt(np.mean((y - y_hat)**2))\n",
        "  return RMSE\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "52aH-ML6Seu7"
      },
      "source": [
        "Even though the RMSE is generally the preferred performance measure for\n",
        "regression tasks, in some contexts you may prefer to use another function. For\n",
        "example, suppose that there are many outliers. In that case, you may\n",
        "consider using the mean absolute error (MAE). It's direct translation of l1 and l2 norm. The higher the norm index, the more it focuses on large values and\n",
        "neglects small ones. This is why the RMSE is more sensitive to\n",
        "outliers than the MAE. But when outliers are exponentially rare (like\n",
        "in a bell-shaped curve), the RMSE performs very well and is\n",
        "generally preferred.\n",
        "\n",
        "MAE can be calculated as follows:\n",
        "\n",
        "$MAE = \\frac{1}{n}\\sum_{t=1}^{n}|\\hat{y}_t - y_t|$\n",
        "\n",
        "- Implementing a function for MAE **mean_absolute_error**, which receives the same parameters *X*, *y*, and *theta*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uFEGAF7fqqeg"
      },
      "outputs": [],
      "source": [
        "def mean_absolute_error(X, y, theta):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_test: data instances to test\n",
        "    - y_test: true values of the corresponding data instances (X_test)\n",
        "    - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "    - MAE: MAE score\n",
        "\n",
        "  Use predict function to calculate our predicted values.\n",
        "  \"\"\"\n",
        "  y_hat = predict(X, theta)\n",
        "  MAE = np.mean(np.abs(y-y_hat) )\n",
        "  return MAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNC0hszHqyIP"
      },
      "source": [
        "Train your regression model on the **standardized** training set and evaluate your method with two different scores: RMSE and MAE. Print two scores here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wm8gHjCSq64P"
      },
      "outputs": [],
      "source": [
        "# rmse_score = rooted_mean_squared_error(X_test_standardized, y_test, theta) # CHANGE IT!\n",
        "# mae_score = mean_absolute_error(X_test_standardized, y_test, theta) # CHANGE IT!\n",
        "rmse_score = rooted_mean_squared_error(X_train_standardized, y_train, theta) \n",
        "mae_score = mean_absolute_error(X_train_standardized, y_train, theta) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWaJtiItrmDk",
        "outputId": "ba786a85-0aad-45b1-9c6e-57b1a7be2cba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7218937315055918, 0.5296562692287425)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse_score, mae_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "royxfFHjRjw2"
      },
      "source": [
        "### 4. Linear regression with regularization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wphcDNvvkwL0"
      },
      "source": [
        "\n",
        "\n",
        "A closed form solution to Ridge can be represented as follows:\n",
        "\n",
        "$\\theta = (\\textbf{X}^T \\cdot \\textbf{X} + \\lambda \\textbf{I})^{-1} \\cdot \\textbf{X}^T \\cdot \\textbf{y}$\n",
        "\n",
        "where $\\textbf{I}$ is an $(n+1) \\times (n+1) $ identity matrix, since the feature matrix also includes the bias column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jvYlCgotRlcK"
      },
      "outputs": [],
      "source": [
        "def solver_with_ridge(X, y, alpha):\n",
        "  \"\"\"\n",
        "  Get the weights and bias of the linear regression line on the dataset X, using the labels y.\n",
        "\n",
        "  Input: \n",
        "   - X: a set of features to get weights\n",
        "   - y: class labels\n",
        "  Output:\n",
        "   - theta: weights and bias of the ridge regression\n",
        "  \"\"\"\n",
        "  bias = np.ones([X.shape[0],1])\n",
        "  data_X = np.concatenate([X,bias],axis=1)\n",
        "  I = np.eye(X.shape[1]+1)\n",
        "  theta = np.linalg.inv(data_X.T @ data_X + (alpha * I)) @ data_X.T @ y\n",
        "  return theta\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G-LrDqWSmaGW"
      },
      "source": [
        "Here, comparing the performances changing the $\\lambda$ value. Use the $\\lambda$ value from 0 to 30 in increments of 0.1. Use RMSE as a score metric. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Vd9pJ8zUo_7u"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = []\n",
        "alpha_values = np.arange(0, 30.0, 0.1)\n",
        "for alpha in alpha_values:\n",
        "    score = rooted_mean_squared_error(X_test_standardized,y_test,solver_with_ridge(X_train_standardized, y_train, alpha))\n",
        "    scores.append(score)\n",
        "len(scores)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ILjT1k5FpLVe"
      },
      "source": [
        "Plotting the graph of different scores here. The resulting plot behaves in a different way based on your split training and test sets. Sometimes, the error just decreases or increases, but you can also see that the error decreases first, but after some point, it starts to increase. If you are interested, repeat many times to check different plots and you can even change the range from [0, 30] to something else. Uncomment the block below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "--Ky0LHO0wqM"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAGwCAYAAABxbMuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABZBElEQVR4nO3deVxVdf7H8dcFvICsAgqiuO+KSyimWZphWJZZuY9rVlNjTcXUoM2oWb8ZnBzTSjMrSq3MpazMylzSGgtFxSVciExFZXEHQdnuPb8/HG9DooKCh+X9fDzOI+853/Plc09H75tzv+d7LIZhGIiIiIhImXMyuwARERGRqkpBS0RERKScKGiJiIiIlBMFLREREZFyoqAlIiIiUk4UtERERETKiYKWiIiISDlxMbuA6sxut5OamoqXlxcWi8XsckRERKQEDMPg7NmzBAcH4+R05WtWClomSk1NJSQkxOwyRERE5BocPnyY+vXrX7GNgpaJvLy8gAv/o7y9vU2uRkREREoiKyuLkJAQx+f4lShomeji14Xe3t4KWiIiIpVMSYb9aDC8iIiISDlR0BIREREpJwpaIiIiIuVEQUtERESknChoiYiIiJQTBS0RERGRcqKgJSIiIlJOFLREREREyomCloiIiEg5UdASERERKScKWiIiIiLlREFLREREpJyYHrTmzJlDo0aNcHNzo2vXrsTHx1+2ba9evbBYLJcs/fr1A6CgoIDo6GhCQ0Px8PAgODiYUaNGkZqaWqSfhIQE+vTpg6+vL/7+/jz66KNkZ2cXabNu3Tq6d++Ol5cXQUFBREdHU1hYWKTNrl27uPXWW3FzcyMkJISXX365jI6KiIiIXK+ElNMcP5tnag2mBq0lS5YQFRXFlClTSEhIoEOHDkRGRnLs2LFi2y9fvpy0tDTHkpiYiLOzM4MGDQLg3LlzJCQkMGnSJBISEli+fDlJSUn079/f0UdqaioRERE0a9aMzZs3s2rVKnbv3s2YMWMcbXbu3Mndd99N37592b59O0uWLGHFihVMmDDB0SYrK4s777yThg0bsm3bNqZPn84LL7zAW2+9VT4HS0REREosbv9J/vD2Zv7wziZO5eSbV4hhovDwcGP8+PGO1zabzQgODjZiYmJKtP/MmTMNLy8vIzs7+7Jt4uPjDcA4dOiQYRiGMW/ePKNOnTqGzWZztNm1a5cBGMnJyYZhGMbEiRONzp07F+lnxYoVhpubm5GVlWUYhmG88cYbRq1atYy8vDxHm+joaKNly5Ylqt0wDCMzM9MAjMzMzBLvIyIiIle2Mfm40fLvXxkNo1caI97ZZJzPLyzT/kvz+W3aFa38/Hy2bdtGRESEY52TkxMRERHExcWVqI/Y2FiGDh2Kh4fHZdtkZmZisVjw9fUFIC8vD6vVipPTb2/d3d0dgI0bNzrauLm5FenH3d2d3Nxctm3bBkBcXBy33XYbVqvV0SYyMpKkpCROnz5dbC15eXlkZWUVWURERKTsfPfzcR6av4XcAju3t6zN26M641bD2bR6TAtaJ06cwGazERgYWGR9YGAg6enpV90/Pj6exMREHn744cu2yc3NJTo6mmHDhuHt7Q1A7969SU9PZ/r06eTn53P69GnHV4JpaWnAhcD0448/8tFHH2Gz2Th69CgvvvhikTbp6enF1n5xW3FiYmLw8fFxLCEhIVd9nyIiIlIy6/cd45EFW8krtBPROpA3R4aZGrKgAgyGv1axsbGEhoYSHh5e7PaCggIGDx6MYRjMnTvXsb5t27YsWLCAGTNmULNmTYKCgmjcuDGBgYGOq1x33nkn06dP57HHHsPV1ZUWLVpw9913AxS5ElZaEydOJDMz07EcPnz4mvsSERGR36zdk8Gj728l32Ynsm0gb/zhJlxdzA1ZYGLQCggIwNnZmYyMjCLrMzIyCAoKuuK+OTk5LF68mHHjxhW7/WLIOnToEGvWrHFczbpo+PDhpKenc/ToUU6ePMkLL7zA8ePHadKkiaNNVFQUZ86cISUlhRMnTnDfffcBONoEBQUVW/vFbcVxdXXF29u7yCIiIiLX5+uf0njsg20U2Az6hdZl9vCbsLpUjGtJplVhtVoJCwtj3bp1jnV2u51169bRrVu3K+67bNky8vLyGDFixCXbLoas5ORk1q5di7+//2X7CQwMxNPTkyVLluDm5kafPn2KbLdYLAQHB+Pu7s5HH31ESEgIN910EwDdunXj+++/p6CgwNF+zZo1tGzZklq1apXoGIiIiMj1+XzHUZ74aDuFdoP7Ogbz6tCO1HCuGCELwMXMHx4VFcXo0aPp3Lkz4eHhzJo1i5ycHMaOHQvAqFGjqFevHjExMUX2i42NZcCAAZeEqIKCAgYOHEhCQgIrV67EZrM5xkv5+fk5Bq7Pnj2b7t274+npyZo1a3juueeYNm2aY8A8wPTp0+nbty9OTk4sX76cadOmsXTpUpydL1yGHD58OFOnTmXcuHFER0eTmJjIq6++ysyZM8vrcImIiMj/WLb1MH/9ZBeGAQPD6vOvB9vj7GQxu6yiyvR+x2vw+uuvGw0aNDCsVqsRHh5ubNq0ybGtZ8+exujRo4u037dvnwEYq1evvqSvAwcOGECxy/r16x3tRo4cafj5+RlWq9Vo3769sXDhwkv6uv322w0fHx/Dzc3N6Nq1q/HVV19d0mbnzp1Gjx49DFdXV6NevXrGtGnTSvXeNb2DiIjItflw0yGjYfRKo2H0SmPi8l2GzWa/YT+7NJ/fFsMwDNNSXjWXlZWFj48PmZmZGq8lIiJSQu/9cICpX+wBYOwtjZh8Txsslht3Jas0n9+mfnUoIiIiUhrzvttPzNf7APhjzyZM6Nvqhoas0lLQEhERkUrhtXXJvLLmZwD+3LsZz/RpUaFDFihoiYiISAVnGAYzVv/M7PW/APDsnS14ondzk6sqGQUtERERqbAMwyDm63289f2vAPzt7tY8cluTq+xVcShoiYiISIVkGAZTv9jD/B8PAjC1f1tGd29kak2lpaAlIiIiFY7dbvC3zxL5KD4FiwX+MSCU4V0bmF1WqSloiYiISIVisxv89eNdfJJwBCcLvDywAwPD6ptd1jVR0BIREZEKo9BmJ2rpTlbsTMXZycLMIR3p3yHY7LKumYKWiIiIVAj5hXaeWrydrxPTqeFs4fVhnejbrq7ZZV0XBS0RERExXW6BjfEfJrBu3zGszk7MHXETd7QONLus66agJSIiIqbKLbDxyMKt/Cf5BK4uTrw9qjO3tahtdlllQkFLRERETHMuv5Bx87cS9+tJ3Gs4EzumM92bBphdVplR0BIRERFTZOUW8NB7W9h66DSeri68N7YLXRr5mV1WmVLQEhERkRvuVE4+o9+N56ejmXi7ubDgoXA6NahldlllTkFLREREbqhjWbmMiN3MzxnZ+HtYeX9cV9oEe5tdVrlQ0BIREZEb5uiZ8/zh7U0cPHmOQG9XPnz4ZprV8TS7rHKjoCUiIiI3xIETOYx4ZzNHz5wnxM+dD8fdTAP/mmaXVa4UtERERKTcJaWfZUTsZo6fzaNJbQ8+fLgrdX3czS6r3CloiYiISLn66UgmI9/dzJlzBbQK8uKDh7sS4Olqdlk3hIKWiIiIlJstB0/x0HtbOJtXSIcQXxaM7YJvTavZZd0wCloiIiJSLjYmn+CRhVs5X2Cja2M/Ysd0wdO1ekWP6vVuRURE5IZYuyeDP32YQL7NTs8WtXlzRBjuVmezy7rhFLRERESkTH2xM5Vnluyg0G7Qt20Qrw7riKtL9QtZoKAlIiIiZWjplsNEL9+FYcD9neoxfWB7XJydzC7LNApaIiIiUibe++EAU7/YA8Dwrg34v/va4eRkMbkqcyloiYiIyHWbs/4Xpn+TBMAjtzbm+btbY7FU75AFCloiIiJyHQzDYPo3SbyxYT8AT93RnKcjmitk/ZeCloiIiFwTu93gxZV7mP/jQQCev7sVj97W1NyiKhgFLRERESk1m91g4vJdLN16BICXBrRj5M0NTa6q4lHQEhERkVLJL7QTtXQHK3el4WSB6QM78GBYfbPLqpAUtERERKTEzufbePzDbWxIOk4NZwuvDe3EXaF1zS6rwlLQEhERkRLJyi3g4flbiT94CrcaTrw5IoxeLeuYXVaFpqAlIiIiV3UyO49R78azOzULLzcX3h3ThS6N/Mwuq8JT0BIREZErSj1znhGxm/n1eA7+HlYWjgunbbCP2WVVCgpaIiIiclm/Hs9mZGw8R8+cJ9jHjQ8e7kqT2p5ml1VpKGiJiIhIsfakZjHq3c2cyM6nSYAH7z/clXq+7maXVakoaImIiMglth48xdj5WzibW0ibut4sHBdOgKer2WVVOgpaIiIiUsR3Px/nj+9vJbfATpdGtXhndBd83GuYXValpKAlIiIiDl/9lMZTi7dTYDPo2aI2b44Iw93qbHZZlZaCloiIiACwZEsKE5f/hN2Afu3rMnNwR6wuTmaXVakpaImIiAhvf/8r//hqLwDDwkP4vwGhODtZTK6q8lPQEhERqcYMw+CVNT/z+re/APDHnk2Y0LcVFotCVllQ0BIREamm7HaDqV/sZkHcIQD+2rclf+rVzOSqqhYFLRERkWqowGbnrx/v4tPtR7FY4MX72jHy5oZml1XlKGiJiIhUM7kFNp5YtJ21ezNwcbIwY3AH7utYz+yyqiQFLRERkWokK7eARxZsZfOBU7i6ODF3xE30bhVodllVloKWiIhINXH8bB5j3otnd2oWnq4uvDO6Mzc38Te7rCpNQUtERKQaOHzqHCNjN3Pw5DkCPK3MHxtOu3o+ZpdV5SloiYiIVHH70rMYFRvPsbN51K/lzvvjutI4wMPssqoFBS0REZEqbOvBUzw0fwtZuYW0DPRi4bhwAr3dzC6r2lDQEhERqaK+3ZfBnz5MILfATueGtYgd3QWfmno49I2koCUiIlIFfbr9CM8u24XNbtC7VR3mDL9JD4c2gYKWiIhIFRO78QAvrdwDwAOd6vGvge2p4ayHQ5tBQUtERKSKMAyDf69OYs76/QCM69GYv93dGic9HNo0CloiIiJVgM1u8PfPEvkoPgWA5yJb8qdeTfVwaJMpaImIiFRyeYU2nl68g68T03GywD/uD2VYeAOzyxIUtERERCq17LxCHl24lR/3n8Tq7MRrwzrSt11ds8uS/zJ9ZNycOXNo1KgRbm5udO3alfj4+Mu27dWrFxaL5ZKlX79+ABQUFBAdHU1oaCgeHh4EBwczatQoUlNTi/STkJBAnz598PX1xd/fn0cffZTs7OwibbZs2cIdd9yBr68vtWrVIjIykp07dzq2Hzx4sNhaNm3aVIZHR0RE5PJOZOcx7K1N/Lj/JB5WZ+aP7aKQVcGYGrSWLFlCVFQUU6ZMISEhgQ4dOhAZGcmxY8eKbb98+XLS0tIcS2JiIs7OzgwaNAiAc+fOkZCQwKRJk0hISGD58uUkJSXRv39/Rx+pqalERETQrFkzNm/ezKpVq9i9ezdjxoxxtMnOzqZv3740aNCAzZs3s3HjRry8vIiMjKSgoKBITWvXri1SU1hYWNkfKBERkd85cvocg9+M46ejmfh5WPno0Zvp3izA7LLk9wwThYeHG+PHj3e8ttlsRnBwsBETE1Oi/WfOnGl4eXkZ2dnZl20THx9vAMahQ4cMwzCMefPmGXXq1DFsNpujza5duwzASE5ONgzDMLZs2WIARkpKymXbHDhwwACM7du3l/j95ubmGpmZmY7l8OHDBmBkZmaWuA8REZGk9Cwj/B9rjIbRK43uMeuM/cfOml1StZKZmVniz2/Trmjl5+ezbds2IiIiHOucnJyIiIggLi6uRH3ExsYydOhQPDwu/7ymzMxMLBYLvr6+AOTl5WG1WnFy+u2tu7u7A7Bx40YAWrZsib+/P7GxseTn53P+/HliY2Np3bo1jRo1KtJ///79qVOnDj169GDFihVXrDcmJgYfHx/HEhISUqL3KSIictG2Q6cY9GYcGVl5NK/jySePd6dJbU+zy5LLMC1onThxApvNRmBgYJH1gYGBpKenX3X/+Ph4EhMTefjhhy/bJjc3l+joaIYNG4a3tzcAvXv3Jj09nenTp5Ofn8/p06eZMGECAGlpaQB4eXmxYcMGPvjgA9zd3fH09GTVqlV8/fXXuLhcuH/A09OTGTNmsGzZMr788kt69OjBgAEDrhi2Jk6cSGZmpmM5fPjwVd+niIjIRWv2ZDD87c1kni+gUwNflj3WjSAfPbewIjN9MPy1io2NJTQ0lPDw8GK3FxQUMHjwYAzDYO7cuY71bdu2ZcGCBcyYMYOaNWsSFBRE48aNCQwMdFzlOn/+POPGjeOWW25h06ZN/PDDD7Rr145+/fpx/vx5AAICAoiKiqJr16506dKFadOmMWLECKZPn37Zml1dXfH29i6yiIiIlMTi+BT++P5W8grt3NGqDosevhnfmlazy5KrMG16h4CAAJydncnIyCiyPiMjg6CgoCvum5OTw+LFi3nxxReL3X4xZB06dIhvv/32kkAzfPhwhg8fTkZGBh4eHlgsFl555RWaNGkCwKJFizh48CBxcXGO8LVo0SJq1arF559/ztChQ4v9uV27dmXNmjUlev8iIiIlYRgGr3/7C6+s+RmAwZ3r88/7Q3HRI3UqBdP+L1mtVsLCwli3bp1jnd1uZ926dXTr1u2K+y5btoy8vDxGjBhxybaLISs5OZm1a9fi7+9/2X4CAwPx9PRkyZIluLm50adPH+DC3YtOTk5FZtO9+Nput1+2vx07dlC3rm6rFRGRsmGzG0z6PNERsp64vRn/erC9QlYlYuqEpVFRUYwePZrOnTsTHh7OrFmzyMnJYezYsQCMGjWKevXqERMTU2S/2NhYBgwYcEmIKigoYODAgSQkJLBy5UpsNptjvJefnx9W64VLrLNnz6Z79+54enqyZs0annvuOaZNm+YYMN+nTx+ee+45xo8fz5NPPondbmfatGm4uLhw++23A7BgwQKsViudOnUCLkw98e677/LOO++U2/ESEZHqI7fgwmzvq3anY7HA1P5tGdWtkdllSSmZGrSGDBnC8ePHmTx5Munp6XTs2JFVq1Y5BsinpKQUuTsQICkpiY0bN7J69epL+jt69KhjMHrHjh2LbFu/fj29evUCLgyknzJlCtnZ2bRq1Yp58+YxcuRIR9tWrVrxxRdfMHXqVLp164aTkxOdOnVi1apVRa5YvfTSSxw6dAgXFxdatWrFkiVLGDhwYFkcGhERqcYyzxfwyMKtxB84hdXZiVlDO3J3qL4xqYwshmEYZhdRXWVlZeHj40NmZqYGxouICADpmbmMfjeepIyzeLm68NaoznRrevlhMHLjlebzW886FBERqSB+OXaWUbHxpGbmUsfLlfljw2kTrF/EKzMFLRERkQpg26HTjFuwhTPnCmhS24MFY8MJ8atpdllynRS0RERETLZubwbjFyWQW2CnY4gv747pgp+H5siqChS0RERETLRkSwrPf5qIzW5we8vazPnDTdS06uO5qtD/SRERERMYhsGc9b/w79UX5sgaGFafmAdCqaE5sqoUBS0REZEbzGY3mPrFbhbGHQJg/O1NefbOlkUmypaqQUFLRETkBsotsPHMkh18nXhhItIp97RhzC2NzS5LyomCloiIyA2Sea6AR97/bSLSV4Z04J72wWaXJeVIQUtEROQGOHL6HGPe28Ivx7LxcnVh3qgwujcNMLssKWcKWiIiIuVsd2omY9/bwrGzeQR5u/He2C60rquJSKsDBS0REZFy9P3Px3n8g23k5NtoGejF/Ie6UNfH3eyy5AZR0BIRESknH287woRPdlFoN+jWxJ83R4bh417D7LLkBlLQEhERKWO/nyOrf4dgpg9qj6uLs8mVyY2moCUiIlKGCm12Jn2+m4/iUwB4rGdT/hrZEicnzZFVHSloiYiIlJFz+YU8sWg73+47hsUCU/u3ZVS3RmaXJSZS0BIRESkDx8/mMW7BFnYdycTVxYnXhnUism2Q2WWJyRS0RERErtOvx7MZ894WUk6do1bNGrwzugthDWuZXZZUAApaIiIi1yEh5TTj5m/h9LkCQvzcWTA2nCa1Pc0uSyoIBS0REZFrtHp3Ok9+tJ28Qjvt6/sQO7oLtb1czS5LKhAFLRERkWuwMO4gL6zYjd2A3q3qMHt4J2pa9bEqRemMEBERKQW73eDlb5J487v9AAwLD+Gl+9rh4uxkcmVSESloiYiIlFBeoY3oj3fx2Y5UAP7SpwVP9G6GxaI5sqR4CloiIiIlkHmugEff38rmA6dwcbIQ80AogzqHmF2WVHAKWiIiIleRcvIcY+bH8+vxHDxdXXjjDzdxW4vaZpcllYCCloiIyBVsTznNwwu2cjInn2AfN94d24VWQd5mlyWVhIKWiIjIZaxKTOOpxTvIK7TTNtibd8d0IdDbzeyypBJR0BIREfkdwzCI3XiAf3y1F+O/0ze8PqwTHq762JTS0RkjIiLyPwptdl5cuYeFcYcAGHFzA164t62mb5BroqAlIiLyXzl5hfz5o+2s23cMiwWev6s1D9/aWNM3yDVT0BIREQEysnJ5aP4Wdqdm4erixKwhHbkrtK7ZZUklp6AlIiLV3r70LB56bwupmbn4e1h5e3RnbmpQy+yypApQ0BIRkWptY/IJHv9gG2fzCmlS24P5Y8Jp4F/T7LKkilDQEhGRamvplsM8/+lPFNoNwhv78dbIMHxrWs0uS6oQBS0REal2DMNgxuqfmb3+FwDu6xjMywPb4+ribHJlUtUoaImISLWSV2jjrx/v4vP/Phj6z72b8UyfFrqzUMqFgpaIiFQbp3Py+eP724g/eOHB0P98IJTBejC0lCMFLRERqRYOnMhh3Pwt/HoiBy9XF+aOCKNH8wCzy5IqTkFLRESqvE2/nuSxD7Zx5lwB9XzdeXdMF1oGeZldllQDCloiIlKlLdt64c7CAptBhxBf3h4VRh0vPRhabgwFLRERqZLsdoN/r07ijQ37AejXvi4zBnXArYbuLJQbR0FLRESqnPP5Nv6ybAdf/ZQOwJO9m/FMRAucnHRnodxYCloiIlKlHMvK5ZGFW9l5JJMazhamPdCeB8Pqm12WVFMKWiIiUmXsTcti3PwLzyysVbMG80Z2Jryxn9llSTWmoCUiIlXCt/syeHLRdnLybTQJ8ODdMV1oFOBhdllSzSloiYhIpWYYBu/9cJD/+3IPdgO6N/Vn7h/C8KlZw+zSRBS0RESk8iq02Zn6xR7e33QIgKFdQnhpQDtqODuZXJnIBQpaIiJSKWXlFvDEou18//NxLBaYeFcrHrm1iZ5ZKBWKgpaIiFQ6h0+d46H5W0g+lo17DWdmDe1IZNsgs8sSuYSCloiIVCrbDp3m0YVbOZmTT6C3K7Gju9Cuno/ZZYkUS0FLREQqjRU7U3l22U7yC+20DfYmdnQXgnz0OB2puBS0RESkwrPbDV5dl8yr65IBiGgdyKtDO+Lhqo8xqdh0hoqISIV2Pt/Gs8t28uVPaQA8cmtjJtzVGmc9TkcqAQUtERGpsNIyz/PIwq0kHs2ihrOF/xvQjiFdGphdlkiJKWiJiEiFtOPwGR5duJVjZ/Pw87Ay9w830bWJv9lliZSKgpaIiFQ4n+84yl8/3kVeoZ0WgZ7Eju5CiF9Ns8sSKTUFLRERqTDsdoOZa3/m9W9/AeCOVnWYNbQjXm56nI5UTqY/o2DOnDk0atQINzc3unbtSnx8/GXb9urVC4vFcsnSr18/AAoKCoiOjiY0NBQPDw+Cg4MZNWoUqampRfpJSEigT58++Pr64u/vz6OPPkp2dnaRNlu2bOGOO+7A19eXWrVqERkZyc6dO4u02bVrF7feeitubm6EhITw8ssvl9FRERGpfs7lF/KnDxMcIeuPtzXhrVGdFbKkUjM1aC1ZsoSoqCimTJlCQkICHTp0IDIykmPHjhXbfvny5aSlpTmWxMREnJ2dGTRoEADnzp0jISGBSZMmkZCQwPLly0lKSqJ///6OPlJTU4mIiKBZs2Zs3ryZVatWsXv3bsaMGeNok52dTd++fWnQoAGbN29m48aNeHl5ERkZSUFBAQBZWVnceeedNGzYkG3btjF9+nReeOEF3nrrrfI7YCIiVVTqmfMMnBvHqt3pWJ2dmD6wPRPv1p2FUgUYJgoPDzfGjx/veG2z2Yzg4GAjJiamRPvPnDnT8PLyMrKzsy/bJj4+3gCMQ4cOGYZhGPPmzTPq1Klj2Gw2R5tdu3YZgJGcnGwYhmFs2bLFAIyUlJTLtnnjjTeMWrVqGXl5eY420dHRRsuWLUtUu2EYRmZmpgEYmZmZJd5HRKSq2XbolBH20hqjYfRKI+yl1caWAyfNLknkikrz+W3aFa38/Hy2bdtGRESEY52TkxMRERHExcWVqI/Y2FiGDh2Kh4fHZdtkZmZisVjw9fUFIC8vD6vVipPTb2/d3d0dgI0bNwLQsmVL/P39iY2NJT8/n/PnzxMbG0vr1q1p1KgRAHFxcdx2221YrVZHP5GRkSQlJXH69Olia8nLyyMrK6vIIiJSnX26/QhD39rEiew8WgV58dn4W+jcyM/sskTKjGlB68SJE9hsNgIDA4usDwwMJD09/ar7x8fHk5iYyMMPP3zZNrm5uURHRzNs2DC8vb0B6N27N+np6UyfPp38/HxOnz7NhAkTAEhLuzAZnpeXFxs2bOCDDz7A3d0dT09PVq1axddff42Ly4X7B9LT04ut/eK24sTExODj4+NYQkJCrvo+RUSqIrvd4F+r9vHMkguP07mzTSCfPN6d+rV0Z6FULaYPhr9WsbGxhIaGEh4eXuz2goICBg8ejGEYzJ0717G+bdu2LFiwgBkzZlCzZk2CgoJo3LgxgYGBjqtc58+fZ9y4cdxyyy1s2rSJH374gXbt2tGvXz/Onz9/zTVPnDiRzMxMx3L48OFr7ktEpLLKySvkjx9sY+6G/QD8qVdT3hwRpsfpSJVk2lkdEBCAs7MzGRkZRdZnZGQQFBR0xX1zcnJYvHgxL774YrHbL4asQ4cO8e233zquZl00fPhwhg8fTkZGBh4eHlgsFl555RWaNGkCwKJFizh48CBxcXGO8LVo0SJq1arF559/ztChQwkKCiq2duCy9bu6uuLq6nrF9yYiUpUdOX2OhxdsZV/6WawuTrz8YHsGdKpndlki5ca0K1pWq5WwsDDWrVvnWGe321m3bh3dunW74r7Lli0jLy+PESNGXLLtYshKTk5m7dq1+PtffhbhwMBAPD09WbJkCW5ubvTp0we4cPeik5MTFstvd7tcfG232wHo1q0b33//veMuRIA1a9bQsmVLatWqVbKDICJSjWw7dIoBc35gX/pZAjxdWfzozQpZUuWZ+tVhVFQUb7/9NgsWLGDv3r08/vjj5OTkMHbsWABGjRrFxIkTL9kvNjaWAQMGXBKiCgoKGDhwIFu3buXDDz/EZrORnp5Oeno6+fn5jnazZ88mISGBn3/+mTlz5vDEE08QExPjGDDfp08fTp8+zfjx49m7dy+7d+9m7NixuLi4cPvttwMXropZrVbGjRvH7t27WbJkCa+++ipRUVHldLRERCqvpVsOM+ytzZzIzqdNXW9WPHELNzXQL6VS9Zn6hfiQIUM4fvw4kydPJj09nY4dO7Jq1SrHoPKUlJQidwcCJCUlsXHjRlavXn1Jf0ePHmXFihUAdOzYsci29evX06tXL+DCQPopU6aQnZ1Nq1atmDdvHiNHjnS0bdWqFV988QVTp06lW7duODk50alTJ1atWkXdunUB8PHxYfXq1YwfP56wsDACAgKYPHkyjz76aFkdHhGRSq/AZucfX+5l/o8HAbirXRAzBnegplXjsaR6sBiGYZhdRHWVlZWFj48PmZmZl4wjExGp7E7n5POnDxOI+/UkAFF9WvDE7c1w0iSkUsmV5vNbv1KIiEiZ25eexSMLt3L41Hk8rM7MHNKRO9te+UYnkapIQUtERMrU1z+l8ZdlOzmXb6OBX03eHtWZlkFeZpclYgoFLRERKRN2u8Gsdcm8ti4ZgB7NApg9vBO+Na1X2VOk6lLQEhGR65adV0jUkh2s3nNhPsGHbmnM83e3wsW50s6LLVImFLREROS6HDqZwyMLt/JzRjZWZyf+cX87BnXWI8ZEQEFLRESuw8bkE4xflEDm+QLqeLkyb2QYnTQ/loiDgpaIiJSaYRi8+8NB/vHlHuwGdAjx5a2RYQR6u5ldmkiFoqAlIiKlkltg4++fJfLxtiMAPHhTff5xfzvcajibXJlIxVOqUYrHjh274vbCwkLi4+OvqyAREam4MrJyGfrWJj7edgQnC0y6pw3/HtReIUvkMkoVtOrWrVskbIWGhnL48GHH65MnT171gdAiIlI5bU85zb2vb2TH4TP4uNdgwUPhjOvRGItFM72LXE6pvjr8/dN6Dh48SEFBwRXbiIhI5ffxtiM8/+lP5BfaaV7Hk7dHdaZRgIfZZYlUeGU+Rku/2YiIVB35hXb+78s9LIw7BECfNoHMHNIRT1cN8RUpCf1NERGRYh07m8v4DxPYcvA0AE9HNOfPvZvrodAipVCqoGWxWDh79ixubm4YhoHFYiE7O5usrCwAx39FRKRyS0g5zeMfbCMjKw8vVxdmDulIRJtAs8sSqXRKPUarRYsWRV536tSpyGt9dSgiUrl9FJ/ClM93k2+z06yOJ2+NDKNJbU+zyxKplEoVtNavX19edYiIiMnyCm28sGIPH8WnANC3bRD/HtxB47FErkOp/vb07NmzvOoQERETZWTl8tgH29iecgaLBZ69syV/6tVU31KIXKdSBa3CwkJsNhuurq6OdRkZGbz55pvk5OTQv39/evToUeZFiohI+dly8BSPf5DAiew8vN1ceG1YJ3q1rGN2WSJVQqmC1iOPPILVamXevHkAnD17li5dupCbm0vdunWZOXMmn3/+OXfffXe5FCsiImXHMAw+2HSIqV/sodBu0CrIi3kjw2jor/mxRMpKqWaG/+GHH3jwwQcdrxcuXIjNZiM5OZmdO3cSFRXF9OnTy7xIEREpW7kFNv768S4mfb6bQrvBPe3rsvxP3RWyRMpYqYLW0aNHad68ueP1unXrePDBB/Hx8QFg9OjR7N69u2wrFBGRMpV65jyD58Wx7L/PK3z+7la8PqwTNa0a9C5S1koVtNzc3Dh//rzj9aZNm+jatWuR7dnZ2WVXnYiIlKm4/Se59/WN7DqSSa2aNVj4UFcevU2D3kXKS6mCVseOHXn//fcB+M9//kNGRga9e/d2bN+/fz/BwcFlW6GIiFw3wzB4d+MBRsRu5mROPm3qerPiiR70aB5gdmkiVVqprhNPnjyZu+66i6VLl5KWlsaYMWOoW7euY/unn37KLbfcUuZFiojItTufb+P5T3/i0+1HAbi/Uz3+eX8o7lZnkysTqfpKPY/Wtm3bWL16NUFBQQwaNKjI9o4dOxIeHl6mBYqIyLU7eCKHxz7Yxr70szg7Wfh7v9aM6d5IXxWK3CAWwzAMs4uorrKysvDx8SEzMxNvb2+zyxGRKmbNngyilu7gbG4hAZ6uzB7eiZub+JtdlkilV5rP71Jd0fr+++9L1O62224rTbciIlKGbHaDGauTeGPDfgA6N6zFnD/cRKC3m8mViVQ/pQpavXr1clxuvtyFMIvFgs1mu/7KRESk1E5m5/Hnxdv54ZeTAIy9pRHP392aGs6luvdJRMpIqYJWrVq18PLyYsyYMYwcOZKAAN2tIiJSUWxPOc2fPkwgLTOXmlZnpj3Ynv4ddCe4iJlK9StOWloa//rXv4iLiyM0NJRx48bx448/4u3tjY+Pj2MREZEbxzAM3o87yOB5caRl5tKktgefjb9FIUukAihV0LJarQwZMoRvvvmGffv20b59e5544glCQkL429/+RmFhYXnVKSIixTifbyNq6U4mfb6bApvBXe2C+Hz8LbQI9DK7NBGhDO46PHDgAOPGjeO7777j+PHj+Pn5lVVtVZ7uOhSR6/H7qRsm9G3Fw7c21tQNIuWsNJ/f1zQ6Mi8vj0WLFhEREUG7du0ICAjgyy+/VMgSEblB1uzJ4N7ZG9mXfpYAT1c+fLgrj9zWRCFLpIIp1WD4+Ph43nvvPRYvXkyjRo0YO3YsS5cuVcASEblBNHWDSOVSqq8OnZycaNCgAaNHjyYsLOyy7fr3718mxVV1+upQREpDUzeIVAyl+fwuddC6Gs2jVXIKWiJSUpq6QaTiKLeZ4e12+1XbnDt3rjRdiojIFRiGwfubDvHSyj0U2Aya1PbgzRFhuqtQpJIos+vNeXl5vPLKKzRp0qSsuhQRqday8wr58+IdTP7v1A1922rqBpHKplRBKy8vj4kTJ9K5c2e6d+/OZ599BsC7775L48aNmTlzJs8880x51CkiUq3sS8+i/+sb+WJnKi5OFv7erzVzR9yEl1sNs0sTkVIo1VeHkydPZt68eURERPDjjz8yaNAgxo4dy6ZNm3jllVcYNGgQzs7O5VWriEi1sGzrYSZ9nkhugZ26Pm7MHt6JsIa6u1ukMipV0Fq2bBkLFy6kf//+JCYm0r59ewoLC9m5c6fmbhERuU7n821MWZHI0q1HALitRW1mDemIn4fV5MpE5FqVKmgdOXLEMa1Du3btcHV15ZlnnlHIEhG5Tr8ez+ZPHyawL/0sThZ4JqIF429vhpOT/n0VqcxKFbRsNhtW62+/Wbm4uODp6VnmRYmIVCcrd6US/fEucvJtBHhaeW1oJ7o3CzC7LBEpA6UKWoZhMGbMGFxdXQHIzc3lsccew8PDo0i75cuXl12FIiJVVF6hjX9+uZcFcYcACG/sx+xhnaijWd5FqoxSBa3Ro0cXeT1ixIgyLUZEpLo4fOocTyxKYOeRTAD+1KspUX1a4KJZ3kWqlFIFrffee6+86hARqTbW7c0gaulOMs8X4ONeg5lDOtC7VaDZZYlIOShV0BIRkWtXaLMzfXUS8777FYAOIb7MGd6J+rVqmlyZiJQXBS0RkRsgPTOXP3+0nfiDpwAY0/3CA6GtLvqqUKQqU9ASESlnG5NP8NTi7ZzMycfT1YWXB7bn7tC6ZpclIjeAgpaISDmx2Q1eW5fMa98mYxjQKsiLuSPCaBzgcfWdRaRKUNASESkHGVm5PLV4O5t+vfBV4ZDOIUy9ry1uNfSYMpHqREFLRKSMbUg6RtTSnZzKycfD6sw/7g9lQKd6ZpclIiZQ0BIRKSMFNjv//p+7CtvU9Wb28E40qa0naIhUVwpaIiJl4Mjpczz50Xa2p5wBYFS3hjx/d2t9VShSzSloiYhcp292p/Pcsp1k5Rbi5ebCyw+25y7dVSgiKGiJiFyzvEIbMV/tY/6PB4ELE5DOHtaJED9NQCoiF1SImfLmzJlDo0aNcHNzo2vXrsTHx1+2ba9evbBYLJcs/fr1A6CgoIDo6GhCQ0Px8PAgODiYUaNGkZqaWqSfhIQE+vTpg6+vL/7+/jz66KNkZ2c7ts+fP7/Yn2OxWDh27BgAGzZsKHZ7enp6ORwlEalIDp7I4cG5PzpC1qO3NWHZH7spZIlIEaYHrSVLlhAVFcWUKVNISEigQ4cOREZGOsLM7y1fvpy0tDTHkpiYiLOzM4MGDQLg3LlzJCQkMGnSJBISEli+fDlJSUn079/f0UdqaioRERE0a9aMzZs3s2rVKnbv3s2YMWMcbYYMGVLk56SlpREZGUnPnj2pU6dOkZqSkpKKtPv9dhGpWlbsTOWe1zeSeDSLWjVr8O6YzprlXUSKZ5gsPDzcGD9+vOO1zWYzgoODjZiYmBLtP3PmTMPLy8vIzs6+bJv4+HgDMA4dOmQYhmHMmzfPqFOnjmGz2Rxtdu3aZQBGcnJysX0cO3bMqFGjhrFw4ULHuvXr1xuAcfr06RLV+nuZmZkGYGRmZl7T/iJyY53PLzQmfLLLaBi90mgYvdIYNPdHI/XMObPLEpEbrDSf36b++pWfn8+2bduIiIhwrHNyciIiIoK4uLgS9REbG8vQoUPx8Lj8TMuZmZlYLBZ8fX0ByMvLw2q14uT029t3d3cHYOPGjcX2sXDhQmrWrMnAgQMv2daxY0fq1q1Lnz59+OGHHy5bR15eHllZWUUWEakcfjl2lvtm/8BH8SlYLPBk72YseqQrdX3czS5NRCowU4PWiRMnsNlsBAYGFlkfGBhYonFO8fHxJCYm8vDDD1+2TW5uLtHR0QwbNgxvb28AevfuTXp6OtOnTyc/P5/Tp08zYcIEANLS0ortJzY2luHDhzsCGUDdunV58803+eSTT/jkk08ICQmhV69eJCQkFNtHTEwMPj4+jiUkJOSq71FEzPfxtiPc+/oPJGWcJcDTlfcf6spf7myJi7O+KhSRK6vU/0rExsYSGhpKeHh4sdsLCgoYPHgwhmEwd+5cx/q2bduyYMECZsyYQc2aNQkKCqJx48YEBgYWucp1UVxcHHv37mXcuHFF1rds2ZI//vGPhIWF0b17d9599126d+/OzJkzi61n4sSJZGZmOpbDhw9fx7sXkfKWnVdI1JIdPLtsJ+cLbNzSzJ+vnupBj+YBZpcmIpWEqdM7BAQE4OzsTEZGRpH1GRkZBAUFXXHfnJwcFi9ezIsvvljs9osh69ChQ3z77beOq1kXDR8+nOHDh5ORkYGHhwcWi4VXXnmFJk2aXNLXO++8Q8eOHQkLC7vqewoPD7/s14+urq64urpetQ8RMd+uI2f480fbOXjyHE4WiOrTgsd7NcPZyWJ2aSJSiZh6RctqtRIWFsa6desc6+x2O+vWraNbt25X3HfZsmXk5eUxYsSIS7ZdDFnJycmsXbsWf3//y/YTGBiIp6cnS5Yswc3NjT59+hTZnp2dzdKlSy+5mnU5O3bsoG5dTVQoUlnZ7QbzvtvPA2/8yMGT56jn686SP3bjid7NFbJEpNRMn7A0KiqK0aNH07lzZ8LDw5k1axY5OTmMHTsWgFGjRlGvXj1iYmKK7BcbG8uAAQMuCVEFBQUMHDiQhIQEVq5cic1mc4z38vPzw2q1AjB79my6d++Op6cna9as4bnnnmPatGmOAfMXLVmyhMLCwmID3axZs2jcuDFt27YlNzeXd955h2+//ZbVq1eX1eERkRvo2Nlc/rJ0J/9JPgHA3aFBxNzfHp+aNUyuTEQqK9OD1pAhQzh+/DiTJ08mPT2djh07smrVKscA+ZSUlEvGTSUlJbFx48ZiA83Ro0dZsWIFcOFuwP+1fv16evXqBVwYSD9lyhSys7Np1aoV8+bNY+TIkZf0FxsbywMPPHBJAIMLd03+5S9/4ejRo9SsWZP27duzdu1abr/99ms4EiJipvX7jvHssp2czMnHrYYTL9zbliFdQrBYdBVLRK6dxTAMw+wiqqusrCx8fHzIzMy8ZAyZiNwYeYU2/vV1Eu/+cACA1nW9eX1YR5rV8TK5MhGpqErz+W36FS0REbPsP57Nk4u2syftwpx2Y7o3YsJdrXCr4WxyZSJSVShoiUi1YxgGy7YeYcqK3ZwvsOHnYWX6wPbc0Trw6juLiJSCgpaIVCuZ5wt4/tOf+HLXhcmJb2nmzyuDOxLo7WZyZSJSFSloiUi1se3QKf780Q6OnjmPi5OFv9zZkj/e1gQnTdsgIuVEQUtEqjyb3eCN9b8wa10yNrtBA7+avDasEx1DfM0uTUSqOAUtEanSjp45T9SSHWw+cAqA+zvV48X72uLlprmxRKT8KWiJSJW1Ymcqf/v0J87mFuJhdealAe144Kb6ZpclItWIgpaIVDlncwuY8vlulm8/CkDHEF9mDelIowAPkysTkepGQUtEqpStB0/x9JIdHDl9HicLPNG7OU/2bkYNZ1Mf7Soi1ZSClohUCQU2O6+tS2bO+l+wGxDi586sIR0Ja+hndmkiUo0paIlIpXfgRA5PL9nBzsNnAHjwpvq80L+NBryLiOkUtESk0jIMg6VbDzP1iz2cy7fh7ebCPx8I5Z72wWaXJiICKGiJSCV1OiefCct38c3uDABubuLHK4M7EuzrbnJlIiK/UdASkUrnP8nH+cvSnRw7m0cNZwvP3tmSR27VDO8iUvEoaIlIpZFbYOPlVUm8+8MBAJrV8WTWkI60q+djcmUiIsVT0BKRSmFfehZPL97BvvSzAIy8uSHP390ad6uzyZWJiFyegpaIVGh2u0HsxgNMX51EfqGdAE8rLw9sT+9WgWaXJiJyVQpaIlJhHTl9jr8s3el4TmHvVnX414Ptqe3lanJlIiIlo6AlIhWOYRh8vO0IU7/YQ3ZeITWtzvy9XxuGhYdgsWjAu4hUHgpaIlKhnMzO4/lPf3JM2xDWsBavDO5AQ389p1BEKh8FLRGpMNbuyWDC8l2cyM6nhrOFpyNa8FjPpjhr2gYRqaQUtETEdNl5hbz0xR6WbD0MQItAT2YO6UjbYE3bICKVm4KWiJgq/sAp/rJsB4dPncdigYd7NOYvd7bErYambRCRyk9BS0RMkVdo45U1P/PW979iGFDP150ZgztwcxN/s0sTESkzCloicsPtTcvimSW/TT46MKw+U+5tg5dbDZMrExEpWwpaInLD2OwGb//nV15Z/TP5Njt+HlZiHgglsm2Q2aWJiJQLBS0RuSEOnczh2WU72XLwNAARresQ84AmHxWRqk1BS0TKld1u8OHmQ/zzq32cL7DhYXVm8r1tGNxZk4+KSNWnoCUi5ebwqXNEf7KLH/efBODmJn5MH9iBEL+aJlcmInJjKGiJSJkzDIPFWw7zfyv3kJNvw62GExP6tmJUt0Y4afJREalGFLREpEylZZ4n+pOf+P7n48CFR+j8e1AHGgfoEToiUv0oaIlImTAMg08SjjL1i92czS3E6uLEc3e25KEejfUIHRGpthS0ROS6HTuby/PLf2Lt3mMAdKjvw4zBHWhWx8vkykREzKWgJSLXzDAMVuxMZcqK3Zw5V+B4EPQfb2uCi7OT2eWJiJhOQUtErsnJ7Dz+/lkiXyemA9A22JsZgzvQKsjb5MpERCoOBS0RKbWvf0rj758lcjInHxcnC0/0bsb425tRQ1exRESKUNASkRI7nZPPlBW7WbEzFYBWQV78e1AH2tXzMbkyEZGKSUFLRErkq5/SmPx5Iiey83GywOO9mvLnO5rj6uJsdmkiIhWWgpaIXNHxs3lM/vy3sVgtAj15eWAHOob4mluYiEgloKAlIsUyDIPPd6TywhcX7ih0drLwp15NeaJ3M13FEhEpIQUtEblEemYuf//st3mx2tT15uWB7TUWS0SklBS0RMTBMAyWbT3CS1/u4WxuITWcLfy5d3Me69VUdxSKiFwDBS0RAeDI6XNMXP4T/0k+AVyY3f3lgR1oGaTZ3UVErpWClkg1Z7cbfBifwrSv9pKTb8Pq4sRf+rRgXI/Gmt1dROQ6KWiJVGOHTuYQ/ckuNv16CoDODWvxr4HtaVrb0+TKRESqBgUtkWrIZjeY/+NBpn+zj9wCO+41nPlr35aM6tYIZyeL2eWJiFQZCloi1cwvx84S/clPbDt0GoCbm/jxrwfb09Dfw+TKRESqHgUtkWoiv9DO3A37mbP+F/Jtdjyszky8uzXDwxvgpKtYIiLlQkFLpBrYdug0E5fv4ueMbAB6tazNP+4PpZ6vu8mViYhUbQpaIlVYdl4h//4miQVxBzEM8POwMuXeNvTvEIzFoqtYIiLlTUFLpIpav+8Yf/8skaNnzgPwwE31+Hu/Nvh5WE2uTESk+lDQEqliTmbnMfWLPazYmQpA/Vru/PP+UG5rUdvkykREqh8FLZEqwjAMPt1+lJdW7uH0uQKcLPDQLY2JurMFNa36qy4iYgb96ytSBRw+dY7nP/3t8Tmtgrz414Pt6RDia25hIiLVnIKWSCVmsxu898MBZqz+mfMFFx6f89QdzXn0tiZ6CLSISAWgoCVSSe1Ny2LCJ7vYeSQTgK6N/Yh5IJQmenyOiEiFoaAlUsmcz7fx2rfJvP39rxTaDbzcXHj+7tYM6RyiiUdFRCqYCvHdwpw5c2jUqBFubm507dqV+Pj4y7bt1asXFovlkqVfv34AFBQUEB0dTWhoKB4eHgQHBzNq1ChSU1OL9JOQkECfPn3w9fXF39+fRx99lOzsbMf2+fPnF/tzLBYLx44dc7TbsGEDN910E66urjRr1oz58+eX7cER+R/rk45x56zvmLthP4V2g8i2gayN6skwze4uIlIhmR60lixZQlRUFFOmTCEhIYEOHToQGRlZJMz8r+XLl5OWluZYEhMTcXZ2ZtCgQQCcO3eOhIQEJk2aREJCAsuXLycpKYn+/fs7+khNTSUiIoJmzZqxefNmVq1axe7duxkzZoyjzZAhQ4r8nLS0NCIjI+nZsyd16tQB4MCBA/Tr14/bb7+dHTt28PTTT/Pwww/zzTfflN8Bk2rpWFYu4xclMPa9LRw+dZ5gHzfeHtWZeSM7E+jtZnZ5IiJyGRbDMAwzC+jatStdunRh9uzZANjtdkJCQnjyySeZMGHCVfefNWsWkydPJi0tDQ+P4h+Ku2XLFsLDwzl06BANGjTgrbfeYtKkSaSlpeHkdCFr/vTTT7Rv357k5GSaNWt2SR/Hjx+nXr16xMbGMnLkSACio6P58ssvSUxMdLQbOnQoZ86cYdWqVZf0kZeXR15enuN1VlYWISEhZGZm4u3tfdX3KtWP3W7wYXwKL3+9j7N5hY4pG57p0wIPV33zLyJihqysLHx8fEr0+W3qFa38/Hy2bdtGRESEY52TkxMRERHExcWVqI/Y2FiGDh162ZAFkJmZicViwdfXF7gQeKxWqyNkAbi7X3jm28aNG4vtY+HChdSsWZOBAwc61sXFxRWpHSAyMvKytcfExODj4+NYQkJCSvQepXrak5rFA3N/ZNJniZzNK6RDfR9WPNGDv9/TRiFLRKSSMDVonThxApvNRmBgYJH1gYGBpKenX3X/+Ph4EhMTefjhhy/bJjc3l+joaIYNG+ZInb179yY9PZ3p06eTn5/P6dOnHVfP0tLSiu0nNjaW4cOHOwIZQHp6erG1Z2Vlcf78+Uv6mDhxIpmZmY7l8OHDV32PUv2cyy8k5qu93Dt7IzsOn8HT1YWp/duy/E+30K6ej9nliYhIKZg+Rut6xMbGEhoaSnh4eLHbCwoKGDx4MIZhMHfuXMf6tm3bsmDBAmbMmEHNmjUJCgqicePGBAYGFrnKdVFcXBx79+5l3Lhx11Wvq6sr3t7eRRaR//Xtvgz6vPI9877/FZvd4O7QINZG9WR090Y4a7C7iEilY+r3DwEBATg7O5ORkVFkfUZGBkFBQVfcNycnh8WLF/Piiy8Wu/1iyDp06BDffvvtJaFm+PDhDB8+nIyMDDw8PLBYLLzyyis0adLkkr7eeecdOnbsSFhYWJH1QUFBxdbu7e1d5MqXyNVkZOUy9YvdfPXThSu59XzdefG+ttzROvAqe4qISEVm6hUtq9VKWFgY69atc6yz2+2sW7eObt26XXHfZcuWkZeXx4gRIy7ZdjFkJScns3btWvz9/S/bT2BgIJ6enixZsgQ3Nzf69OlTZHt2djZLly4t9mpWt27ditQOsGbNmqvWLnKRzW6w4MeD3DHjO776KR1nJwt/vK0Ja6JuU8gSEakCTB9RGxUVxejRo+ncuTPh4eHMmjWLnJwcxo4dC8CoUaOoV68eMTExRfaLjY1lwIABl4SogoICBg4cSEJCAitXrsRmsznGe/n5+WG1WgGYPXs23bt3x9PTkzVr1vDcc88xbdo0x4D5i5YsWUJhYWGxge6xxx5j9uzZ/PWvf+Whhx7i22+/ZenSpXz55ZdldXikCks8msnfPv3JMbN7xxBf/nl/KG2C9ZWyiEhVYXrQGjJkCMePH2fy5Mmkp6fTsWNHVq1a5RhknpKScsm4qaSkJDZu3Mjq1asv6e/o0aOsWLECgI4dOxbZtn79enr16gVcGEg/ZcoUsrOzadWqFfPmzXNM2/C/YmNjeeCBBy4JYACNGzfmyy+/5JlnnuHVV1+lfv36vPPOO0RGRl7DkZDqIvN8ATNWJ/HBpkPYDfBydeGvd7VieHgDjcMSEaliTJ9HqzorzTwcUvkZhsGn24/yz6/2ciI7H4D+HYL5e7/W1NGkoyIilUZpPr9Nv6IlUh0kpZ9l0ueJxB84BUDT2h68dF87ujcLMLkyEREpTwpaIuUoO6+QV9f+zLs/HMRmN3Cv4cyTdzTj4R5NsLpU6tlVRESkBBS0RMqBYRh89VM6L63cQ3pWLgB3tglk8r1tqF+rpsnViYjIjaKgJVLGfj2ezZQVu/lP8gkAGvjVZGr/ttzeqo7JlYmIyI2moCVSRs7n23hjwy/M++5X8m12rC5OPN6zKY/3aopbDWezyxMRERMoaImUgbV7Mnjhi90cOX3hGZc9W9Rmav+2NAq4/MPORUSk6lPQErkOh0+dY+oXe1i798KjmIJ93Jh8bxsi2wZhsWhOLBGR6k5BS+QanM+3Mfe7/cz7bj95hXZcnCw8fGsT/nxHM2pa9ddKREQu0CeCSCkYhsHXien848u9HD1z4WvC7k39mdq/Lc0DvUyuTkREKhoFLZES+jnjLFO/2M0Pv5wEoJ6vO3/v15q+7fQ1oYiIFE9BS+QqsnILmLUmmQVxFyYdtbo48VjPpjzesynuVt1NKCIil6egJXIZdrvBxwlHeHnVPsezCe9sE8ike9oQ4qdJR0VE5OoUtESKsePwGaas2M3Ow2cAaFLbgxfubcttLWqbW5iIiFQqCloi/+NEdh4vr9rH0q1HAPB0deGpO5ozunsjPZtQRERKTUFLBCiw2Xk/7hAz1/7M2dxCAB64qR4T+raijrebydWJiEhlpaAl1d4Pv5xg6he7+TkjG4B29byZ2r8tYQ39TK5MREQqOwUtqbYOnMjhH1/udczqXqtmDf7atxWDO4fg7KTpGkRE5PopaEm1k3m+gNnfJjP/x4MU2AycnSyMvLkhT0c0x7em1ezyRESkClHQkmqj0GZnydbDzFj9M6dyLkzX0Ktlbf7erzXN6mhWdxERKXsKWlIt/PDLCV5auYd96WcBaFrbg7/f04bbW9YxuTIREanKFLSkSvv9OCwf9xo8E9GcP9zckBrOmq5BRETKl4KWVElZuQW8vk7jsERExFwKWlKl2OwGi7ek8Mrqnzn533FYPVvUZtI9GoclIiI3noKWVBk//nKCFzUOS0REKhAFLan0fjmWzbSv92kcloiIVDgKWlJpncjO49W1ySyKT8Fm/20c1lN3NKeWh8ZhiYiI+RS0pNLJLbARu/EAczfsJzvvwnMJI1oHMuGuVjSr42lydSIiIr9R0JJKw243+GzHUaZ/k0RaZi4AofV8eP7u1nRr6m9ydSIiIpdS0JJK4cdfTvCPr/ayOzULgHq+7jwX2ZL+HYJx0nMJRUSkglLQkgotOeMsMV/v49t9xwDwcnXhT7c3Y+wtjXCr4WxydSIiIlemoCUV0vGzecxc+zOL41OwG+DiZGHEzQ15sncz/D1dzS5PRESkRBS0pEI5n2/jnf/8ypvf7Scn3wZAZNtAovu2okltDXQXEZHKRUFLKgSb3eCThCO8svpn0rMuDHTvUN+Hv/VrQ3hjP5OrExERuTYKWmIqwzBYu/cY07/Zx88Z2cCFge7Rd7XintC6GuguIiKVmoKWmGbLwVP86+t9bD10Grgwo/v425syqpsGuouISNWgoCU3XFL6WaZ/s4+1ey/cSehWw4mHbmnMH3s2xce9hsnViYiIlB0FLblhjp45z8w1P/NJwhEMA5ydLAzuHMLTEc0J9HYzuzwREZEyp6Al5e50Tj5z1v/Cwk2HyC+0A3BXuyCejWxJU91JKCIiVZiClpSbc/mFvPfDQd7csJ+z/30m4c1N/Iju24pODWqZXJ2IiEj5U9CSMldgs7N062FmrU3m+Nk8AFrX9Sa6b0t6tqiNxaI7CUVEpHpQ0JIyY7cbfJ2Yzr9XJ3HgRA4A9Wu58+ydeiahiIhUTwpact0Mw2B90jH+/c3P7Em78NBnPw8rT/ZuxvCuDXB10VQNIiJSPSloyXX5cf8J/v1NEgkpZwDwsDoz7tYmPHJrY7zcNFWDiIhUbwpack0SUk4zY3USP/xyEgBXFydGd2/EYz2b4udhNbk6ERGRikFBS0plT2oWM1YnsW7fhclGazhbGBbegPG3N9NcWCIiIr+joCUlsv94Nq+s+Zkvd6UB4GSBB2+qz5/vaE6IX02TqxMREamYFLTkig6fOser65JZnnAEu3Fh3T3t6/JMnxaabFREROQqFLSkWBlZucz+9hcWb0mhwHYhYUW0rkNUn5a0CfY2uToREZHKQUFLijiRncdb3//Kgh8Pkvffx+X0aBbAX+5sodncRURESklBS4ALAevt739lYdwhzhfYAAhrWItn72xJt6b+JlcnIiJSOSloVXMns/N46z+/svDH3wJWh/o+PB3Rgl4t9bgcERGR66GgVU0VF7Da1/fh6Yjm3N6yjgKWiIhIGVDQqmZO5eTz1ve/sjDuIOfyFbBERETKk4JWNXEqJ5+3/3NhkPvFgBVa70LA6t1KAUtERKQ8KGhVccUFrHb1vHn6jhbc0VoBS0REpDwpaFVRp/8nYOUoYImIiJjCyewC5syZQ6NGjXBzc6Nr167Ex8dftm2vXr2wWCyXLP369QOgoKCA6OhoQkND8fDwIDg4mFGjRpGamlqkn4SEBPr06YOvry/+/v48+uijZGdnX/Lz5s+fT/v27XFzc6NOnTqMHz/ese3gwYPF1rJp06YyOjLXbtuh0/T417e8sWE/Ofk22gZ78/aoznzxRA8i2gQqZImIiNwgpgatJUuWEBUVxZQpU0hISKBDhw5ERkZy7NixYtsvX76ctLQ0x5KYmIizszODBg0C4Ny5cyQkJDBp0iQSEhJYvnw5SUlJ9O/f39FHamoqERERNGvWjM2bN7Nq1Sp2797NmDFjivysV155hb/97W9MmDCB3bt3s3btWiIjIy+pae3atUVqCgsLK7sDdI3aBnvj4epCm7revDUyjJVP9qCPApaIiMiNZ5goPDzcGD9+vOO1zWYzgoODjZiYmBLtP3PmTMPLy8vIzs6+bJv4+HgDMA4dOmQYhmHMmzfPqFOnjmGz2Rxtdu3aZQBGcnKyYRiGcerUKcPd3d1Yu3btZfs9cOCAARjbt28vUa3FyczMNAAjMzPzmvu4nJSTOYbdbi/zfkVERKq70nx+m3ZFKz8/n23bthEREeFY5+TkREREBHFxcSXqIzY2lqFDh+Lh4XHZNpmZmVgsFnx9fQHIy8vDarXi5PTbW3d3dwdg48aNAKxZswa73c7Ro0dp3bo19evXZ/DgwRw+fPiS/vv370+dOnXo0aMHK1asuGK9eXl5ZGVlFVnKS4hfTV3BEhERMZlpQevEiRPYbDYCAwOLrA8MDCQ9Pf2q+8fHx5OYmMjDDz982Ta5ublER0czbNgwvL0vPAi5d+/epKenM336dPLz8zl9+jQTJkwAIC0tDYBff/0Vu93OP//5T2bNmsXHH3/MqVOn6NOnD/n5+QB4enoyY8YMli1bxpdffkmPHj0YMGDAFcNWTEwMPj4+jiUkJOSq71NEREQqL9MHw1+r2NhYQkNDCQ8PL3Z7QUEBgwcPxjAM5s6d61jftm1bFixYwIwZM6hZsyZBQUE0btyYwMBAx1Uuu91OQUEBr732GpGRkdx888189NFHJCcns379egACAgKIioqia9eudOnShWnTpjFixAimT59+2ZonTpxIZmamYynuCpmIiIhUHaYFrYCAAJydncnIyCiyPiMjg6CgoCvum5OTw+LFixk3blyx2y+GrEOHDrFmzRrH1ayLhg8fTnp6OkePHuXkyZO88MILHD9+nCZNmgBQt25dANq0aePYp3bt2gQEBJCSknLZurp27covv/xy2e2urq54e3sXWURERKTqMi1oWa1WwsLCWLdunWOd3W5n3bp1dOvW7Yr7Llu2jLy8PEaMGHHJtoshKzk5mbVr1+Lv73/ZfgIDA/H09GTJkiW4ubnRp08fAG655RYAkpKSHG1PnTrFiRMnaNiw4WX727FjhyOkiYiIiJg6YWlUVBSjR4+mc+fOhIeHM2vWLHJychg7diwAo0aNol69esTExBTZLzY2lgEDBlwSogoKChg4cCAJCQmsXLkSm83mGO/l5+eH1WoFYPbs2XTv3h1PT0/WrFnDc889x7Rp0xwD5lu0aMF9993HU089xVtvvYW3tzcTJ06kVatW3H777QAsWLAAq9VKp06dgAtTT7z77ru888475Xa8REREpHIxNWgNGTKE48ePM3nyZNLT0+nYsSOrVq1yDJBPSUkpcncgXLjKtHHjRlavXn1Jf0ePHnUMRu/YsWORbevXr6dXr17AhYH0U6ZMITs7m1atWjFv3jxGjhxZpP3ChQt55pln6NevH05OTvTs2ZNVq1ZRo0YNR5uXXnqJQ4cO4eLiQqtWrViyZAkDBw683sMiIiIiVYTFMAzD7CKqq6ysLHx8fMjMzNR4LRERkUqiNJ/flfauQxEREZGKTkFLREREpJwoaImIiIiUEwUtERERkXKioCUiIiJSThS0RERERMqJqfNoVXcXZ9bIysoyuRIREREpqYuf2yWZIUtBy0Rnz54FICQkxORKREREpLTOnj2Lj4/PFdtowlIT2e12UlNT8fLywmKxlGnfWVlZhISEcPjwYU2GehU6VqWj41VyOlalo+NVcjpWJVcex8owDM6ePUtwcPAlT7D5PV3RMpGTkxP169cv15/h7e2tv4QlpGNVOjpeJadjVTo6XiWnY1VyZX2srnYl6yINhhcREREpJwpaIiIiIuVEQauKcnV1ZcqUKbi6uppdSoWnY1U6Ol4lp2NVOjpeJadjVXJmHysNhhcREREpJ7qiJSIiIlJOFLREREREyomCloiIiEg5UdASERERKScKWlXQnDlzaNSoEW5ubnTt2pX4+HizS6qQXnjhBSwWS5GlVatWZpdVYXz//ffce++9BAcHY7FY+Oyzz4psNwyDyZMnU7duXdzd3YmIiCA5OdmcYk12tWM1ZsyYS861vn37mlOsyWJiYujSpQteXl7UqVOHAQMGkJSUVKRNbm4u48ePx9/fH09PTx588EEyMjJMqtg8JTlWvXr1uuTceuyxx0yq2Fxz586lffv2jolJu3Xrxtdff+3YbtZ5paBVxSxZsoSoqCimTJlCQkICHTp0IDIykmPHjpldWoXUtm1b0tLSHMvGjRvNLqnCyMnJoUOHDsyZM6fY7S+//DKvvfYab775Jps3b8bDw4PIyEhyc3NvcKXmu9qxAujbt2+Rc+2jjz66gRVWHN999x3jx49n06ZNrFmzhoKCAu68805ycnIcbZ555hm++OILli1bxnfffUdqaioPPPCAiVWboyTHCuCRRx4pcm69/PLLJlVsrvr16zNt2jS2bdvG1q1b6d27N/fddx+7d+8GTDyvDKlSwsPDjfHjxzte22w2Izg42IiJiTGxqoppypQpRocOHcwuo1IAjE8//dTx2m63G0FBQcb06dMd686cOWO4uroaH330kQkVVhy/P1aGYRijR4827rvvPlPqqeiOHTtmAMZ3331nGMaF86hGjRrGsmXLHG327t1rAEZcXJxZZVYIvz9WhmEYPXv2NJ566inziqrgatWqZbzzzjumnle6olWF5Ofns23bNiIiIhzrnJyciIiIIC4uzsTKKq7k5GSCg4Np0qQJf/jDH0hJSTG7pErhwIEDpKenFznXfHx86Nq1q861y9iwYQN16tShZcuWPP7445w8edLskiqEzMxMAPz8/ADYtm0bBQUFRc6tVq1a0aBBg2p/bv3+WF304YcfEhAQQLt27Zg4cSLnzp0zo7wKxWazsXjxYnJycujWrZup55UeKl2FnDhxApvNRmBgYJH1gYGB7Nu3z6SqKq6uXbsyf/58WrZsSVpaGlOnTuXWW28lMTERLy8vs8ur0NLT0wGKPdcubpPf9O3blwceeIDGjRuzf/9+nn/+ee666y7i4uJwdnY2uzzT2O12nn76aW655RbatWsHXDi3rFYrvr6+RdpW93OruGMFMHz4cBo2bEhwcDC7du0iOjqapKQkli9fbmK15vnpp5/o1q0bubm5eHp68umnn9KmTRt27Nhh2nmloCXV1l133eX4c/v27enatSsNGzZk6dKljBs3zsTKpKoZOnSo48+hoaG0b9+epk2bsmHDBu644w4TKzPX+PHjSUxM1NjIErjcsXr00Ucdfw4NDaVu3brccccd7N+/n6ZNm97oMk3XsmVLduzYQWZmJh9//DGjR4/mu+++M7UmfXVYhQQEBODs7HzJXRQZGRkEBQWZVFXl4evrS4sWLfjll1/MLqXCu3g+6Vy7Nk2aNCEgIKBan2tPPPEEK1euZP369dSvX9+xPigoiPz8fM6cOVOkfXU+ty53rIrTtWtXgGp7blmtVpo1a0ZYWBgxMTF06NCBV1991dTzSkGrCrFarYSFhbFu3TrHOrvdzrp16+jWrZuJlVUO2dnZ7N+/n7p165pdSoXXuHFjgoKCipxrWVlZbN68WedaCRw5coSTJ09Wy3PNMAyeeOIJPv30U7799lsaN25cZHtYWBg1atQocm4lJSWRkpJS7c6tqx2r4uzYsQOgWp5bxbHb7eTl5Zl6XumrwyomKiqK0aNH07lzZ8LDw5k1axY5OTmMHTvW7NIqnGeffZZ7772Xhg0bkpqaypQpU3B2dmbYsGFml1YhZGdnF/mt+MCBA+zYsQM/Pz8aNGjA008/zf/93//RvHlzGjduzKRJkwgODmbAgAHmFW2SKx0rPz8/pk6dyoMPPkhQUBD79+/nr3/9K82aNSMyMtLEqs0xfvx4Fi1axOeff46Xl5djfIyPjw/u7u74+Pgwbtw4oqKi8PPzw9vbmyeffJJu3bpx8803m1z9jXW1Y7V//34WLVrE3Xffjb+/P7t27eKZZ57htttuo3379iZXf+NNnDiRu+66iwYNGnD27FkWLVrEhg0b+Oabb8w9r8r1nkYxxeuvv240aNDAsFqtRnh4uLFp0yazS6qQhgwZYtStW9ewWq1GvXr1jCFDhhi//PKL2WVVGOvXrzeAS5bRo0cbhnFhiodJkyYZgYGBhqurq3HHHXcYSUlJ5hZtkisdq3Pnzhl33nmnUbt2baNGjRpGw4YNjUceecRIT083u2xTFHecAOO9995ztDl//rzxpz/9yahVq5ZRs2ZN4/777zfS0tLMK9okVztWKSkpxm233Wb4+fkZrq6uRrNmzYznnnvOyMzMNLdwkzz00ENGw4YNDavVatSuXdu44447jNWrVzu2m3VeWQzDMMo3yomIiIhUTxqjJSIiIlJOFLREREREyomCloiIiEg5UdASERERKScKWiIiIiLlREFLREREpJwoaImIiIiUEwUtERERkXKioCUiUkoHDx7EYrE4nitXEvPnz8fX17fcahKRiklBS0RERKScKGiJiIiIlBMFLRGRYqxatYoePXrg6+uLv78/99xzD/v37y+27YYNG7BYLHz55Ze0b98eNzc3br75ZhITEy9p+80339C6dWs8PT3p27cvaWlpjm1btmyhT58+BAQE4OPjQ8+ePUlISCi39ygi5U9BS0SkGDk5OURFRbF161bWrVuHk5MT999/P3a7/bL7PPfcc8yYMYMtW7ZQu3Zt7r33XgoKChzbz507x7///W/ef/99vv/+e1JSUnj22Wcd28+ePcvo0aPZuHEjmzZtonnz5tx9992cPXu2XN+riJQfF7MLEBGpiB588MEir999911q167Nnj178PT0LHafKVOm0KdPHwAWLFhA/fr1+fTTTxk8eDAABQUFvPnmmzRt2hSAJ554ghdffNGxf+/evYv099Zbb+Hr68t3333HPffcU2bvTURuHF3REhEpRnJyMsOGDaNJkyZ4e3vTqFEjAFJSUi67T7du3Rx/9vPzo2XLluzdu9exrmbNmo6QBVC3bl2OHTvmeJ2RkcEjjzxC8+bN8fHxwdvbm+zs7Cv+TBGp2HRFS0SkGPfeey8NGzbk7bffJjg4GLvdTrt27cjPz7/mPmvUqFHktcViwTAMx+vRo0dz8uRJXn31VRo2bIirqyvdunW7rp8pIuZS0BIR+Z2TJ0+SlJTE22+/za233grAxo0br7rfpk2baNCgAQCnT5/m559/pnXr1iX+uT/88ANvvPEGd999NwCHDx/mxIkT1/AORKSiUNASEfmdWrVq4e/vz1tvvUXdunVJSUlhwoQJV93vxRdfxN/fn8DAQP72t78REBDAgAEDSvxzmzdvzvvvv0/nzp3Jysriueeew93d/TreiYiYTWO0RER+x8nJicWLF7Nt2zbatWvHM888w/Tp06+637Rp03jqqacICwsjPT2dL774AqvVWuKfGxsby+nTp7npppsYOXIkf/7zn6lTp871vBURMZnF+N8BAiIiUmobNmzg9ttv5/Tp03rMjogUoStaIiIiIuVEQUtERESknOirQxEREZFyoitaIiIiIuVEQUtERESknChoiYiIiJQTBS0RERGRcqKgJSIiIlJOFLREREREyomCloiIiEg5UdASERERKSf/DyxbhONWJgKtAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(np.arange(0, 30, 0.1), scores)\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3nHFnagh0nC"
      },
      "source": [
        "### 5. Model validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "M7JEfZjGijfH"
      },
      "outputs": [],
      "source": [
        "def repeated_hold_out(X, y, k, test_ratio):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: features\n",
        "    - y: labels\n",
        "    - test_ratio: ratio of the test set\n",
        "  Output:\n",
        "    - score: the average of k different test scores\n",
        "  \n",
        "  1. Iterate k times to perform k validation processes.\n",
        "  2. For each iteration, split the dataset into training and test sets with *random* indices.\n",
        "   - Note that each iteration should create different training and test sets.\n",
        "  3. Use *standardization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "  4. Fit your model with *solver* (without ridge) on the training set.\n",
        "  5. Save your *RMSE* score into the list *scores*\n",
        "  6. After all the iterations, return the average of *scores*.\n",
        "\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(k):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_ratio)\n",
        "    X_train_standardized, X_test_standardized = apply_standardization(X_train, X_test)\n",
        "    theta = solver(X_train_standardized, y_train)\n",
        "    scores.append(rooted_mean_squared_error(X_test_standardized, y_test, theta))\n",
        "  average = sum(scores) / k\n",
        "  return average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QuMGeSGfLjAL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7333994668566514"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "holdout_score = repeated_hold_out(X, y, k=5, test_ratio=0.2)\n",
        "holdout_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7mSIvYbRoQq"
      },
      "source": [
        "### 6. Put things together"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DWjft22LHEJm"
      },
      "source": [
        "\n",
        "* Creating `pipeline` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6CU_kV0DRpYg"
      },
      "outputs": [],
      "source": [
        "def pipeline(X, y, k = 5, test_ratio = 0.2, norm_method = \"standardization\", eval_method = \"RMSE\", alpha = 0):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: features\n",
        "    - y: labels\n",
        "    - test_ratio: ratio of the test set\n",
        "  Output:\n",
        "    - score: the average of k different test scores\n",
        "  \n",
        "  1. Iterate k times to perform k validation processes.\n",
        "  2. For each iteration, split the dataset into the training and test sets with *random* indices.\n",
        "   - Note that each iteration should create different training and test sets.\n",
        "  3. Check the parameter *norm_method*\n",
        "    - if norm_method == standardization:\n",
        "      - Use *standardization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "    - if norm_method == normalization:\n",
        "      - Use *normalization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "  4. Fit your model with *solver_with_ridge\" on the training set. Use alpha from the parameter.\n",
        "  5. Check the parameter \"eval_method\"\n",
        "    - if eval_method == \"RMSE\"\n",
        "      - Save your *RMSE* score into the list *scores*\n",
        "    - if eval_method == \"MAE\"\n",
        "      - Save your *MAE* score into the list *scores*\n",
        "\n",
        "  6. After all the iterations, return the average of *scores*.\n",
        "\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for i in range(k):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_ratio)\n",
        "    if norm_method == 'standardization':\n",
        "      X_train_norm, X_test_norm = apply_standardization(X_train, X_test)\n",
        "    elif norm_method == 'normalization':\n",
        "      X_train_norm, X_test_norm = apply_normalization(X_train, X_test)\n",
        "    else:\n",
        "      X_train_norm = X_train\n",
        "    theta = solver_with_ridge(X_train_norm, y_train, alpha)\n",
        "    if eval_method == 'RMSE':\n",
        "      scores.append(rooted_mean_squared_error(X_test_norm, y_test, theta))\n",
        "    elif eval_method == 'MAE':\n",
        "      scores.append(mean_absolute_error(X_test_norm, y_test, theta))\n",
        "  average = sum(scores) / k\n",
        "\n",
        "  return average"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1682e5d06a6d97c1b1cf6bb4ae6cf16223e994936ddb1d53664597d7d46101fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
